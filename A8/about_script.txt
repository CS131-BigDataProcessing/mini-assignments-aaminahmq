Team Members: Averi Tanlimco, Deema Saddik, Justine Mae Legson, Aaminah Mohammad
We first removed any trailing spaces and new lines in the CSV file so we could accurately identify what missing values were in the file without these being viewed as missing values. 
It is better to replace the missing values with “NA” than to remove the rows with missing values as we’d lose nearly 20% of our data which is significant, especially when the missing data may not be of particular interest when aggregating and visualizing the data later on. Additionally, rows that have null values can still contain important information, meaning that keeping them would result in a better representation of the overall dataset than if they were removed. Also, various Python data processing and visualization packages, such as pandas, already have methods that can deal with null values, such as dropping them from a DataFrame (table), which does not impact the original CSV file. This means there is no need to remove the rows with null values in the actual CSV file itself during the preprocessing stage, as it can always be removed in a more controlled way that preserves the original data better later on.
The mean, median, and mode should not be used as a condition as it is a measure of central tendency. Rather the interquartile ranges should be found and used to identify outliers. Using the mean would only be appropriate after the outliers are removed so it is a more accurate measure of the center of the data. Otherwise, it is important to use the median rather than the mean when working with the data as a replacement value for outliers. That is why the median was used as the replacement value.

